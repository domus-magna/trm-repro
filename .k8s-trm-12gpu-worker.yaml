apiVersion: batch/v1
kind: Job
metadata:
  name: trm-train-arc2-12gpu-worker
spec:
  backoffLimit: 0
  template:
    spec:
      restartPolicy: Never
      nodeName: gd956ec
      nodeSelector:
        gpu.nvidia.com/model: H200
      containers:
        - name: trainer
          image: nvidia/cuda:12.1.0-devel-ubuntu22.04
          imagePullPolicy: IfNotPresent
          env:
            - name: WANDB_API_KEY
              valueFrom:
                secretKeyRef:
                  name: wandb-api-key
                  key: token
            - name: WANDB_MODE
              value: online
            - name: WANDB_PROJECT
              value: trm-arc2
            - name: RDZV_ENDPOINT
              value: trm-12gpu-master:29400
            - name: CUDA_HOME
              value: /usr/local/cuda
          command: ["bash","-lc"]
          args:
            - |
              source /script/common.sh
              cd /workspace/TinyRecursiveModels
              run_name="trm_arc2_12gpu_variant"
              torchrun                 --rdzv_backend=c10d                 --rdzv_endpoint=                 --rdzv_id=                 --nnodes=2:2                 pretrain.py                   arch=trm                   data_paths="[data/arc2concept-aug-1000]"                   arch.L_layers=2                   arch.H_cycles=3 arch.L_cycles=4                   +run_name= ema=True
          volumeMounts:
            - name: trm-workspace
              mountPath: /workspace
            - name: script
              mountPath: /script
          resources:
            limits:
              nvidia.com/gpu: 4
              cpu: "8"
              memory: 48Gi
            requests:
              nvidia.com/gpu: 4
              cpu: "4"
              memory: 24Gi
      volumes:
        - name: trm-workspace
          persistentVolumeClaim:
            claimName: trm-workspace-rwx
        - name: script
          hostPath:
            path: /Users/alexanderhuth/trm-repro/.k8s-trm-common.sh
            type: File
